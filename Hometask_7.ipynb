{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOM5tfKwV3hm+LvGuH6lPt/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tashkinovnet/Home-Task/blob/Hometask_7.ipynb/Hometask_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Hometask 7**"
      ],
      "metadata": {
        "id": "c8PHI8AKp5Ly"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9ZpBC7Sgauk"
      },
      "source": [
        "###Задача: запустить модель LDA и Gibbs Sampling с числов тегов 20. Вывести топ-10 слов по каждому тегу. Соотнести полученные теги с тегами из датасета. Добейтесь того, чтобы хотя бы несколько тем были явно интерпретируемы, например, как в примерах ниже.\n",
        "\n",
        "Примеры топ-10 слов из некотрых тегов, которые получаются после применения LDA:\n",
        "* ['god', 'jesus', 'believe', 'life', 'bible', 'christian', 'world', 'church', 'word', 'people'] - эта группа явно соотносится с soc.religion.christian\n",
        "* ['drive', 'card', 'hard', 'bit', 'disk', 'scsi', 'memory', 'speed', 'mac', 'video'] - эту группу можно соотнести с темами 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware'\n",
        "* ['game',\t'games',\t'hockey',\t'league',\t'play',\t'players',\t'season',\t'team',\t'teams',\t'win'] - тема rec.sport.hockey\n",
        "\n",
        "Советы:\n",
        "* модель будет сходится лучше и быстрее, если уменьшить размер словаря за счет отсеивания общеупотребительных слов и редких слов. Управлять размером словаря можно с помощью параметров min_df (отсеивает слова по минимальной частоте встречаемости) и max_df (отсеивает слова по максимальной частоте встречаемости) в CountVectorizer.\n",
        "* параметры $\\alpha$, $\\beta$ можно, для начала, положить единицами\n",
        "* после 100 итераций можно ожидать хорошего распределения по темам. Если этого не происходит и в темах мешинина - проверяйте код и оптимизируйте словарь\n",
        "* на примере третьей темы видно, что у нас встречаются разные формы одного и того же слова. С помощью процедур stemming и lemmatization можно привести слова к общей форме и объединить близкие по значению"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import numpy as np\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "documents = newsgroups_train.data\n",
        "labels = newsgroups_train.target\n",
        "label_names = newsgroups_train.target_names\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    max_df=0.95,\n",
        "    min_df=2,\n",
        "    stop_words='english',\n",
        "    max_features=1000\n",
        ")\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "n_topics = 20\n",
        "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=100, random_state=42)\n",
        "lda.fit(X)\n",
        "\n",
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    topics = []\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
        "        topics.append(top_words)\n",
        "        print(f\"Topic #{topic_idx + 1}: {', '.join(top_words)}\")\n",
        "    return topics\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "topics = print_top_words(lda, feature_names, 10)\n",
        "\n",
        "# Категории тем\n",
        "topic_assignments = lda.transform(X).argmax(axis=1)\n",
        "topic_to_labels = {i: [] for i in range(n_topics)}\n",
        "\n",
        "# Группировка по темам\n",
        "for i, topic in enumerate(topic_assignments):\n",
        "    topic_to_labels[topic].append(labels[i])\n",
        "\n",
        "for topic_idx, label_list in topic_to_labels.items():\n",
        "    label_counts = np.bincount(label_list, minlength=len(label_names))\n",
        "    top_label_idx = label_counts.argmax()\n",
        "    print(f\"Topic #{topic_idx + 1}: {label_names[top_label_idx]} ({label_counts[top_label_idx]} documents)\")\n",
        "    print(f\"Top words: {', '.join(topics[topic_idx])}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFgk4xNE0nQ_",
        "outputId": "6bc0cd48-d67c-47b9-b9b0-ab6d4ab11ad6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1: key, chip, encryption, keys, clipper, privacy, use, security, public, government\n",
            "Topic #2: god, jesus, bible, christian, believe, church, faith, people, christians, life\n",
            "Topic #3: file, windows, use, window, program, using, output, files, set, entry\n",
            "Topic #4: said, people, armenian, did, didn, went, armenians, came, know, told\n",
            "Topic #5: game, team, year, games, play, season, hockey, players, league, win\n",
            "Topic #6: available, data, software, image, ftp, version, graphics, information, based, program\n",
            "Topic #7: thanks, know, does, help, like, mail, looking, hi, need, advance\n",
            "Topic #8: mr, president, israel, israeli, stephanopoulos, going, think, know, people, jobs\n",
            "Topic #9: government, law, people, state, right, rights, public, laws, military, federal\n",
            "Topic #10: drive, card, scsi, disk, mac, hard, video, pc, use, bit\n",
            "Topic #11: 10, 11, 25, 14, 17, 12, 15, 16, db, 13\n",
            "Topic #12: new, power, time, years, year, high, used, cost, low, air\n",
            "Topic #13: space, 00, nasa, launch, earth, satellite, orbit, shuttle, 02, dos\n",
            "Topic #14: ax, max, g9v, b8f, a86, pl, 145, 1d9, 34u, 1t\n",
            "Topic #15: people, does, think, don, question, say, point, true, just, time\n",
            "Topic #16: april, health, water, medical, use, 1993, research, center, food, men\n",
            "Topic #17: edu, com, list, mail, send, email, internet, faq, cs, address\n",
            "Topic #18: gun, guns, file, control, firearms, crime, dod, media, police, weapons\n",
            "Topic #19: just, don, like, think, good, know, ve, really, make, time\n",
            "Topic #20: 000, turkish, war, jews, world, turkey, jewish, history, greek, university\n",
            "Topic #1: sci.crypt (234 documents)\n",
            "Top words: key, chip, encryption, keys, clipper, privacy, use, security, public, government\n",
            "\n",
            "Topic #2: soc.religion.christian (294 documents)\n",
            "Top words: god, jesus, bible, christian, believe, church, faith, people, christians, life\n",
            "\n",
            "Topic #3: comp.windows.x (341 documents)\n",
            "Top words: file, windows, use, window, program, using, output, files, set, entry\n",
            "\n",
            "Topic #4: talk.politics.mideast (103 documents)\n",
            "Top words: said, people, armenian, did, didn, went, armenians, came, know, told\n",
            "\n",
            "Topic #5: rec.sport.hockey (243 documents)\n",
            "Top words: game, team, year, games, play, season, hockey, players, league, win\n",
            "\n",
            "Topic #6: comp.graphics (140 documents)\n",
            "Top words: available, data, software, image, ftp, version, graphics, information, based, program\n",
            "\n",
            "Topic #7: comp.graphics (116 documents)\n",
            "Top words: thanks, know, does, help, like, mail, looking, hi, need, advance\n",
            "\n",
            "Topic #8: talk.politics.mideast (84 documents)\n",
            "Top words: mr, president, israel, israeli, stephanopoulos, going, think, know, people, jobs\n",
            "\n",
            "Topic #9: talk.politics.guns (67 documents)\n",
            "Top words: government, law, people, state, right, rights, public, laws, military, federal\n",
            "\n",
            "Topic #10: comp.sys.ibm.pc.hardware (276 documents)\n",
            "Top words: drive, card, scsi, disk, mac, hard, video, pc, use, bit\n",
            "\n",
            "Topic #11: rec.sport.hockey (36 documents)\n",
            "Top words: 10, 11, 25, 14, 17, 12, 15, 16, db, 13\n",
            "\n",
            "Topic #12: misc.forsale (77 documents)\n",
            "Top words: new, power, time, years, year, high, used, cost, low, air\n",
            "\n",
            "Topic #13: sci.space (50 documents)\n",
            "Top words: space, 00, nasa, launch, earth, satellite, orbit, shuttle, 02, dos\n",
            "\n",
            "Topic #14: comp.os.ms-windows.misc (13 documents)\n",
            "Top words: ax, max, g9v, b8f, a86, pl, 145, 1d9, 34u, 1t\n",
            "\n",
            "Topic #15: alt.atheism (218 documents)\n",
            "Top words: people, does, think, don, question, say, point, true, just, time\n",
            "\n",
            "Topic #16: sci.med (55 documents)\n",
            "Top words: april, health, water, medical, use, 1993, research, center, food, men\n",
            "\n",
            "Topic #17: misc.forsale (33 documents)\n",
            "Top words: edu, com, list, mail, send, email, internet, faq, cs, address\n",
            "\n",
            "Topic #18: talk.politics.guns (47 documents)\n",
            "Top words: gun, guns, file, control, firearms, crime, dod, media, police, weapons\n",
            "\n",
            "Topic #19: rec.motorcycles (346 documents)\n",
            "Top words: just, don, like, think, good, know, ve, really, make, time\n",
            "\n",
            "Topic #20: talk.politics.mideast (64 documents)\n",
            "Top words: 000, turkish, war, jews, world, turkey, jewish, history, greek, university\n",
            "\n"
          ]
        }
      ]
    }
  ]
}